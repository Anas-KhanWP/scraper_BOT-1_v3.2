2024-03-30 02:40:20,493 - INFO - Started Scraping URL -> 1/1
2024-03-30 02:40:32,419 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-30 03:48:59,299 - INFO - Started Scraping URL -> 1/1
2024-03-30 03:49:02,231 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-30 03:50:30,002 - INFO - Started Scraping URL -> 1/1
2024-03-30 03:50:36,096 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-30 03:52:21,333 - INFO - Excel File mapwise status updated!!!
2024-03-30 03:52:49,007 - INFO - Started Scraping URL -> 1/1
2024-03-30 03:52:56,741 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-30 04:10:56,094 - INFO - Started Scraping URL -> 1/69
2024-03-30 04:11:04,958 - INFO - Getting Foreclosure Dates For -> 1/69
2024-03-30 04:11:47,172 - INFO - Started Scraping URL -> 2/69
2024-03-30 04:11:53,557 - INFO - Getting Foreclosure Dates For -> 2/69
2024-03-30 04:12:32,657 - INFO - Started Scraping URL -> 3/69
2024-03-30 04:12:39,723 - INFO - Getting Foreclosure Dates For -> 3/69
2024-03-30 04:13:15,010 - INFO - Started Scraping URL -> 4/69
2024-03-30 04:13:20,731 - INFO - Getting Foreclosure Dates For -> 4/69
2024-03-30 20:22:49,021 - INFO - Started Scraping URL -> 1/1
2024-03-30 20:33:19,008 - INFO - Started Scraping URL -> 1/1
2024-03-30 20:33:25,468 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-30 20:35:19,477 - INFO - Excel File mapwise status updated!!!
2024-03-31 20:31:16,820 - INFO - Started Scraping URL -> 1/1
2024-03-31 20:31:19,648 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 20:33:30,175 - INFO - Started Scraping URL -> 1/1
2024-03-31 20:33:35,853 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 20:44:13,323 - INFO - Started Scraping URL -> 1/1
2024-03-31 20:44:24,398 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 20:48:41,197 - INFO - Started Scraping URL -> 1/1
2024-03-31 20:48:54,700 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 20:54:50,088 - INFO - Started Scraping URL -> 1/1
2024-03-31 20:54:56,134 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 20:59:17,385 - INFO - Started Scraping URL -> 1/1
2024-03-31 20:59:26,778 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:00:43,956 - INFO - Excel File mapwise status updated!!!
2024-03-31 21:04:39,985 - INFO - Started Scraping URL -> 1/1
2024-03-31 21:04:46,387 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:06:20,818 - INFO - Started Scraping URL -> 1/1
2024-03-31 21:06:31,208 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:09:13,983 - INFO - Started Scraping URL -> 1/1
2024-03-31 21:09:23,699 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:16:17,403 - INFO - Started Scraping URL -> 1/1
2024-03-31 21:16:20,329 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:18:30,754 - INFO - Started Scraping URL -> 1/1
2024-03-31 21:18:40,689 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:19:55,884 - INFO - Excel File mapwise status updated!!!
2024-03-31 21:20:46,131 - INFO - Started Scraping URL -> 1/1
2024-03-31 21:20:54,459 - INFO - Getting Foreclosure Dates For -> 1/1
2024-03-31 21:22:10,033 - INFO - Excel File mapwise status updated!!!
2024-03-31 21:25:05,301 - INFO - Started Scraping URL -> 1/3
2024-03-31 21:25:09,582 - INFO - Getting Foreclosure Dates For -> 1/3
2024-03-31 21:26:03,665 - INFO - Started Scraping URL -> 2/3
2024-03-31 21:26:11,677 - INFO - Getting Foreclosure Dates For -> 2/3
2024-03-31 21:26:56,463 - INFO - Started Scraping URL -> 3/3
2024-03-31 21:27:03,537 - INFO - Getting Foreclosure Dates For -> 3/3
2024-03-31 21:28:12,544 - INFO - Excel File mapwise status updated!!!
2024-04-03 01:34:58,433 - INFO - Started Scraping URL -> 1/1
2024-04-03 01:35:01,058 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-03 01:35:28,978 - INFO - Started Scraping URL -> 1/1
2024-04-03 01:35:35,006 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-03 01:37:19,520 - INFO - Excel File mapwise status updated!!!
2024-04-03 01:41:12,423 - INFO - Started Scraping URL -> 1/1
2024-04-03 01:41:15,247 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-03 01:42:17,379 - INFO - Excel File mapwise status updated!!!
2024-04-03 01:43:33,499 - INFO - Started Scraping URL -> 1/1
2024-04-03 01:43:36,215 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-03 01:44:39,020 - INFO - Excel File mapwise status updated!!!
2024-04-03 19:15:53,086 - INFO - Started Scraping URL -> 1/2
2024-04-03 19:15:59,368 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 19:16:41,678 - INFO - Started Scraping URL -> 2/2
2024-04-03 19:16:48,762 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 19:19:31,632 - INFO - Started Scraping URL -> 1/2
2024-04-03 19:19:42,306 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 19:20:26,358 - INFO - Started Scraping URL -> 2/2
2024-04-03 19:20:33,304 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 19:25:16,853 - INFO - Started Scraping URL -> 1/2
2024-04-03 19:25:27,355 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 19:26:11,774 - INFO - Started Scraping URL -> 2/2
2024-04-03 19:26:21,736 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 19:34:21,909 - INFO - Started Scraping URL -> 1/2
2024-04-03 19:34:31,423 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 19:35:18,567 - INFO - Started Scraping URL -> 2/2
2024-04-03 19:35:25,447 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 19:40:09,376 - INFO - Started Scraping URL -> 1/2
2024-04-03 19:40:15,754 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 19:41:04,497 - INFO - Started Scraping URL -> 2/2
2024-04-03 19:41:13,760 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 19:57:40,402 - INFO - Started Scraping URL -> 1/2
2024-04-03 19:57:50,174 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 19:58:37,479 - INFO - Started Scraping URL -> 2/2
2024-04-03 19:58:46,805 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 20:03:20,572 - INFO - Excel File mapwise status updated!!!
2024-04-03 20:10:37,002 - INFO - Started Scraping URL -> 1/2
2024-04-03 20:10:46,536 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 20:11:33,247 - INFO - Started Scraping URL -> 2/2
2024-04-03 20:11:41,037 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 20:14:30,334 - INFO - Excel File mapwise status updated!!!
2024-04-03 23:26:42,742 - INFO - Started Scraping URL -> 1/2
2024-04-03 23:26:49,499 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-03 23:27:33,981 - INFO - Started Scraping URL -> 2/2
2024-04-03 23:27:40,631 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-03 23:30:44,719 - INFO - Excel File mapwise status updated!!!
2024-04-05 05:04:09,823 - INFO - Started Scraping URL -> 1/2
2024-04-05 05:04:15,990 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-05 05:04:54,731 - INFO - Started Scraping URL -> 2/2
2024-04-05 05:04:59,970 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-05 05:06:21,207 - INFO - Excel File mapwise status updated!!!
2024-04-05 05:09:01,573 - INFO - Started Scraping URL -> 1/2
2024-04-05 05:09:12,136 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-05 05:09:52,157 - INFO - Started Scraping URL -> 2/2
2024-04-05 05:09:58,961 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-05 05:12:31,892 - INFO - Excel File mapwise status updated!!!
2024-04-06 15:33:56,710 - INFO - Started Scraping URL -> 1/69
2024-04-06 15:34:02,784 - INFO - Getting Foreclosure Dates For -> 1/69
2024-04-06 15:34:57,692 - INFO - Started Scraping URL -> 2/69
2024-04-06 15:35:05,811 - INFO - Getting Foreclosure Dates For -> 2/69
2024-04-06 15:35:30,408 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,436 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,441 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,443 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,446 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,453 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,456 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.106)
Stacktrace:
	GetHandleVerifier [0x00007FF75D027072+63090]
	(No symbol) [0x00007FF75CF92CC2]
	(No symbol) [0x00007FF75CE2EC65]
	(No symbol) [0x00007FF75CE0CA7C]
	(No symbol) [0x00007FF75CE9D687]
	(No symbol) [0x00007FF75CEB2AC1]
	(No symbol) [0x00007FF75CE96D83]
	(No symbol) [0x00007FF75CE683A8]
	(No symbol) [0x00007FF75CE69441]
	GetHandleVerifier [0x00007FF75D4225CD+4238285]
	GetHandleVerifier [0x00007FF75D45F72D+4488493]
	GetHandleVerifier [0x00007FF75D457A0F+4456463]
	GetHandleVerifier [0x00007FF75D1005B6+953270]
	(No symbol) [0x00007FF75CF9E58F]
	(No symbol) [0x00007FF75CF99264]
	(No symbol) [0x00007FF75CF9939B]
	(No symbol) [0x00007FF75CF89BD4]
	BaseThreadInitThunk [0x00007FF96B727344+20]
	RtlUserThreadStart [0x00007FF96CDA26B1+33]

2024-04-06 15:35:30,457 - INFO - Started Scraping URL -> 3/69
2024-04-06 15:35:58,560 - INFO - Started Scraping URL -> 1/1
2024-04-06 15:36:08,057 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-06 15:39:04,150 - INFO - Started Scraping URL -> 1/1
2024-04-06 15:39:12,609 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-06 15:48:30,490 - INFO - Excel File mapwise status updated!!!
2024-04-06 16:15:16,194 - INFO - Started Scraping URL -> 1/1
2024-04-06 16:15:18,824 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-06 16:17:11,746 - INFO - Excel File mapwise status updated!!!
2024-04-06 16:41:14,367 - INFO - Started Scraping URL -> 1/1
2024-04-06 16:41:17,096 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-06 16:54:29,870 - INFO - Started Scraping URL -> 1/1
2024-04-06 16:54:43,049 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-06 16:56:40,013 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/citrus_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/citrus_data.csv'
2024-04-06 16:57:46,718 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/citrus_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/citrus_data.csv'
2024-04-06 16:58:15,129 - INFO - Excel File mapwise status updated!!!
2024-04-06 23:12:57,130 - INFO - Started Scraping URL -> 1/6
2024-04-06 23:13:03,918 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-06 23:14:33,541 - INFO - Started Scraping URL -> 2/6
2024-04-06 23:14:41,199 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-06 23:15:31,375 - INFO - Started Scraping URL -> 3/6
2024-04-06 23:15:38,218 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-06 23:16:16,514 - INFO - Started Scraping URL -> 4/6
2024-04-06 23:16:22,216 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-06 23:22:45,219 - INFO - Started Scraping URL -> 5/6
2024-04-06 23:22:52,025 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-06 23:23:53,005 - INFO - Started Scraping URL -> 6/6
2024-04-06 23:24:00,350 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-07 00:18:34,019 - INFO - Started Scraping URL -> 1/6
2024-04-07 00:18:44,750 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-07 00:19:48,609 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:19:58,740 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:20:09,072 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:20:18,845 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:20:28,430 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:20:40,827 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:20:49,959 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/random_data.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 315, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/random_data.csv'
2024-04-07 00:21:36,340 - INFO - Started Scraping URL -> 1/6
2024-04-07 00:21:43,729 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-07 00:22:59,678 - INFO - Started Scraping URL -> 2/6
2024-04-07 00:23:05,510 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-07 00:23:59,363 - INFO - Started Scraping URL -> 3/6
2024-04-07 00:24:07,061 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-07 00:24:49,674 - INFO - Started Scraping URL -> 4/6
2024-04-07 00:24:56,581 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-07 00:31:39,540 - INFO - Started Scraping URL -> 5/6
2024-04-07 00:31:51,690 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-07 00:32:52,224 - INFO - Started Scraping URL -> 6/6
2024-04-07 00:32:58,147 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-07 00:45:56,200 - INFO - Started Scraping URL -> 1/6
2024-04-07 00:46:05,507 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-07 00:47:36,669 - INFO - Started Scraping URL -> 2/6
2024-04-07 00:47:45,520 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-07 00:48:48,865 - INFO - Started Scraping URL -> 3/6
2024-04-07 00:49:00,955 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-07 00:49:44,419 - INFO - Started Scraping URL -> 4/6
2024-04-07 00:49:52,813 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-07 00:56:39,315 - INFO - Started Scraping URL -> 5/6
2024-04-07 00:56:47,256 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-07 00:57:48,365 - INFO - Started Scraping URL -> 6/6
2024-04-07 00:57:56,264 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-07 01:20:20,817 - INFO - Excel File mapwise status updated!!!
2024-04-07 01:29:33,245 - INFO - Started Scraping URL -> 1/6
2024-04-07 01:29:37,940 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-07 01:31:03,809 - INFO - Started Scraping URL -> 2/6
2024-04-07 01:31:11,505 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-07 01:32:09,566 - INFO - Started Scraping URL -> 3/6
2024-04-07 01:32:17,016 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-07 01:32:59,853 - INFO - Started Scraping URL -> 4/6
2024-04-07 01:33:12,986 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-07 01:40:14,637 - INFO - Started Scraping URL -> 5/6
2024-04-07 01:40:22,704 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-07 01:41:39,170 - INFO - Started Scraping URL -> 6/6
2024-04-07 01:41:46,607 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-07 01:55:24,852 - INFO - Excel File mapwise status updated!!!
2024-04-07 02:27:20,572 - INFO - Started Scraping URL -> 1/1
2024-04-07 02:27:29,234 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-07 02:31:15,435 - INFO - Excel File mapwise status updated!!!
2024-04-07 02:37:33,642 - INFO - Started Scraping URL -> 1/1
2024-04-07 02:37:41,600 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-07 02:43:23,030 - INFO - Started Scraping URL -> 1/6
2024-04-07 02:43:32,383 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-07 02:45:17,895 - INFO - Started Scraping URL -> 2/6
2024-04-07 02:45:25,393 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-07 02:52:29,316 - INFO - Started Scraping URL -> 3/6
2024-04-07 02:52:40,214 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-07 02:53:38,283 - INFO - Started Scraping URL -> 4/6
2024-04-07 02:53:44,458 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-07 02:54:24,568 - INFO - Started Scraping URL -> 5/6
2024-04-07 02:54:28,470 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-07 02:55:34,882 - INFO - Started Scraping URL -> 6/6
2024-04-07 02:55:38,788 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-07 03:09:28,364 - INFO - Excel File mapwise status updated!!!
2024-04-07 03:34:06,221 - INFO - Started Scraping URL -> 1/4
2024-04-07 03:34:14,359 - INFO - Getting Foreclosure Dates For -> 1/4
2024-04-07 03:34:50,262 - INFO - Started Scraping URL -> 2/4
2024-04-07 03:35:01,382 - INFO - Getting Foreclosure Dates For -> 2/4
2024-04-07 03:35:39,818 - INFO - Started Scraping URL -> 3/4
2024-04-07 03:35:46,339 - INFO - Getting Foreclosure Dates For -> 3/4
2024-04-07 03:39:06,961 - INFO - Started Scraping URL -> 4/4
2024-04-07 03:42:12,217 - INFO - Started Scraping URL -> 1/4
2024-04-07 03:42:19,143 - INFO - Getting Foreclosure Dates For -> 1/4
2024-04-07 03:42:55,702 - INFO - Started Scraping URL -> 2/4
2024-04-07 03:43:06,077 - INFO - Getting Foreclosure Dates For -> 2/4
2024-04-07 03:43:45,003 - INFO - Started Scraping URL -> 3/4
2024-04-07 03:43:52,577 - INFO - Getting Foreclosure Dates For -> 3/4
2024-04-07 03:45:53,271 - INFO - Started Scraping URL -> 4/4
2024-04-07 03:45:59,929 - INFO - Getting Foreclosure Dates For -> 4/4
2024-04-07 03:54:50,615 - INFO - Excel File mapwise status updated!!!
2024-04-07 04:28:44,543 - INFO - Started Scraping URL -> 1/4
2024-04-07 04:28:54,204 - INFO - Getting Foreclosure Dates For -> 1/4
2024-04-07 04:29:40,489 - INFO - Started Scraping URL -> 2/4
2024-04-07 04:29:52,021 - INFO - Getting Foreclosure Dates For -> 2/4
2024-04-07 04:30:28,942 - INFO - Started Scraping URL -> 3/4
2024-04-07 04:30:34,989 - INFO - Getting Foreclosure Dates For -> 3/4
2024-04-07 04:32:32,870 - INFO - Started Scraping URL -> 4/4
2024-04-07 04:32:39,938 - INFO - Getting Foreclosure Dates For -> 4/4
2024-04-07 04:41:41,004 - INFO - Excel File mapwise status updated!!!
2024-04-07 04:50:28,486 - INFO - Started Scraping URL -> 1/4
2024-04-07 04:50:35,242 - INFO - Getting Foreclosure Dates For -> 1/4
2024-04-07 04:51:09,830 - INFO - Started Scraping URL -> 2/4
2024-04-07 04:51:20,656 - INFO - Getting Foreclosure Dates For -> 2/4
2024-04-07 04:51:57,444 - INFO - Started Scraping URL -> 3/4
2024-04-07 04:52:05,018 - INFO - Getting Foreclosure Dates For -> 3/4
2024-04-07 04:53:55,911 - INFO - Started Scraping URL -> 4/4
2024-04-07 04:54:02,389 - INFO - Getting Foreclosure Dates For -> 4/4
2024-04-14 00:24:36,476 - INFO - Started Scraping URL -> 1/29
2024-04-14 00:24:44,018 - INFO - Getting Foreclosure Dates For -> 1/29
2024-04-14 00:25:32,029 - INFO - Started Scraping URL -> 2/29
2024-04-14 00:25:41,098 - INFO - Getting Foreclosure Dates For -> 2/29
2024-04-14 00:26:56,892 - INFO - Started Scraping URL -> 3/29
2024-04-14 00:27:03,183 - INFO - Getting Foreclosure Dates For -> 3/29
2024-04-14 00:27:58,343 - INFO - Started Scraping URL -> 4/29
2024-04-14 00:28:06,323 - INFO - Getting Foreclosure Dates For -> 4/29
2024-04-14 00:28:43,905 - INFO - Started Scraping URL -> 5/29
2024-04-14 00:28:50,016 - INFO - Getting Foreclosure Dates For -> 5/29
2024-04-14 00:30:26,070 - INFO - Started Scraping URL -> 6/29
2024-04-14 00:30:31,422 - INFO - Getting Foreclosure Dates For -> 6/29
2024-04-14 00:31:07,056 - INFO - Started Scraping URL -> 7/29
2024-04-14 00:31:13,767 - INFO - Getting Foreclosure Dates For -> 7/29
2024-04-14 00:31:51,987 - INFO - Started Scraping URL -> 8/29
2024-04-14 00:31:59,398 - INFO - Getting Foreclosure Dates For -> 8/29
2024-04-14 00:32:45,163 - INFO - Started Scraping URL -> 9/29
2024-04-14 00:32:49,479 - INFO - Getting Foreclosure Dates For -> 9/29
2024-04-14 00:33:21,221 - INFO - Started Scraping URL -> 10/29
2024-04-14 00:33:28,356 - INFO - Getting Foreclosure Dates For -> 10/29
2024-04-14 00:34:09,224 - INFO - Started Scraping URL -> 11/29
2024-04-14 00:34:16,988 - INFO - Getting Foreclosure Dates For -> 11/29
2024-04-14 00:34:47,773 - INFO - Started Scraping URL -> 12/29
2024-04-14 00:34:55,413 - INFO - Getting Foreclosure Dates For -> 12/29
2024-04-14 00:36:40,585 - INFO - Started Scraping URL -> 13/29
2024-04-14 00:36:45,095 - INFO - Getting Foreclosure Dates For -> 13/29
2024-04-14 00:37:43,662 - INFO - Started Scraping URL -> 14/29
2024-04-14 00:37:49,937 - INFO - Getting Foreclosure Dates For -> 14/29
2024-04-14 00:38:39,135 - INFO - Started Scraping URL -> 15/29
2024-04-14 00:38:47,504 - INFO - Getting Foreclosure Dates For -> 15/29
2024-04-14 00:39:01,960 - INFO - Started Scraping URL -> 16/29
2024-04-14 00:39:12,332 - INFO - Getting Foreclosure Dates For -> 16/29
2024-04-14 00:39:51,739 - INFO - Started Scraping URL -> 17/29
2024-04-14 00:39:59,229 - INFO - Getting Foreclosure Dates For -> 17/29
2024-04-14 00:41:29,068 - INFO - Started Scraping URL -> 18/29
2024-04-14 00:41:32,982 - INFO - Getting Foreclosure Dates For -> 18/29
2024-04-14 00:48:12,013 - INFO - Started Scraping URL -> 19/29
2024-04-14 00:48:18,270 - INFO - Getting Foreclosure Dates For -> 19/29
2024-04-14 00:49:02,484 - INFO - Started Scraping URL -> 20/29
2024-04-14 00:49:09,456 - INFO - Getting Foreclosure Dates For -> 20/29
2024-04-14 00:49:24,030 - INFO - Started Scraping URL -> 21/29
2024-04-14 00:49:31,460 - INFO - Getting Foreclosure Dates For -> 21/29
2024-04-14 00:50:45,346 - INFO - Started Scraping URL -> 22/29
2024-04-14 00:50:51,084 - INFO - Getting Foreclosure Dates For -> 22/29
2024-04-14 01:04:18,229 - INFO - Started Scraping URL -> 23/29
2024-04-14 01:04:24,401 - INFO - Getting Foreclosure Dates For -> 23/29
2024-04-14 01:05:09,828 - INFO - Started Scraping URL -> 24/29
2024-04-14 01:05:21,073 - INFO - Getting Foreclosure Dates For -> 24/29
2024-04-14 01:15:47,611 - INFO - Started Scraping URL -> 25/29
2024-04-14 01:15:52,019 - INFO - Getting Foreclosure Dates For -> 25/29
2024-04-14 01:16:30,836 - INFO - Started Scraping URL -> 26/29
2024-04-14 01:16:44,501 - INFO - Getting Foreclosure Dates For -> 26/29
2024-04-14 01:17:34,475 - INFO - Started Scraping URL -> 27/29
2024-04-14 01:17:42,051 - INFO - Getting Foreclosure Dates For -> 27/29
2024-04-14 01:18:17,394 - INFO - Started Scraping URL -> 28/29
2024-04-14 01:18:24,930 - INFO - Getting Foreclosure Dates For -> 28/29
2024-04-14 01:19:00,366 - INFO - Started Scraping URL -> 29/29
2024-04-14 01:19:08,229 - INFO - Getting Foreclosure Dates For -> 29/29
2024-04-14 02:02:48,002 - INFO - Excel File mapwise status updated!!!
2024-04-14 02:51:18,308 - INFO - Started Scraping URL -> 1/2
2024-04-14 02:51:26,947 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 02:52:23,395 - INFO - Started Scraping URL -> 2/2
2024-04-14 02:52:27,771 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 02:53:30,752 - INFO - Started Scraping URL -> 1/2
2024-04-14 02:53:37,699 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 02:54:35,000 - INFO - Started Scraping URL -> 2/2
2024-04-14 02:54:43,433 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 02:57:55,624 - INFO - Started Scraping URL -> 1/2
2024-04-14 02:58:01,608 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 02:58:55,157 - INFO - Started Scraping URL -> 2/2
2024-04-14 02:58:59,128 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 03:00:04,792 - INFO - Excel File mapwise status updated!!!
2024-04-14 20:34:27,894 - INFO - Started Scraping URL -> 1/2
2024-04-14 20:34:36,269 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 20:35:25,433 - INFO - Started Scraping URL -> 2/2
2024-04-14 20:35:36,463 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 20:36:40,780 - INFO - Excel File mapwise status updated!!!
2024-04-14 20:46:38,628 - INFO - Started Scraping URL -> 1/2
2024-04-14 20:46:44,476 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 20:47:41,601 - INFO - Started Scraping URL -> 2/2
2024-04-14 20:47:44,720 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 20:48:58,484 - INFO - Excel File mapwise status updated!!!
2024-04-14 21:09:27,741 - INFO - Started Scraping URL -> 1/2
2024-04-14 21:09:35,971 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 21:10:46,864 - INFO - Started Scraping URL -> 2/2
2024-04-14 21:10:53,232 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 21:13:03,536 - INFO - Started Scraping URL -> 1/2
2024-04-14 21:13:11,707 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 21:14:10,570 - ERROR - Error Occurred in the main function: 'WebDriver' object has no attribute 'pagesource'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 812, in get_owner_info
    auction_items = get_owner_info_gilchrist_realforeclose(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 834, in get_owner_info_gilchrist_realforeclose
    soup = BeautifulSoup(driver.pagesource, 'html.parser')
                         ^^^^^^^^^^^^^^^^^
AttributeError: 'WebDriver' object has no attribute 'pagesource'
2024-04-14 21:14:41,934 - INFO - Started Scraping URL -> 1/2
2024-04-14 21:14:48,041 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 21:15:57,330 - INFO - Started Scraping URL -> 2/2
2024-04-14 21:16:02,582 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 21:16:21,598 - INFO - Started Scraping URL -> 1/2
2024-04-14 21:16:33,581 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 21:17:53,525 - INFO - Started Scraping URL -> 2/2
2024-04-14 21:17:59,732 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 21:36:34,826 - INFO - Started Scraping URL -> 1/2
2024-04-14 21:36:41,990 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 21:38:42,745 - INFO - Started Scraping URL -> 2/2
2024-04-14 21:38:49,331 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 22:09:38,016 - INFO - patching driver executable C:\Users\MAK\appdata\roaming\undetected_chromedriver\undetected_chromedriver.exe
2024-04-14 22:18:58,072 - INFO - Started Scraping URL -> 1/2
2024-04-14 22:19:07,921 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 22:19:13,435 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF012AC1]
	(No symbol) [0x00007FF6DEFF6D83]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF012AC1]
	(No symbol) [0x00007FF6DEFF6D83]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]

2024-04-14 22:19:13,439 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF012AC1]
	(No symbol) [0x00007FF6DEFF6D83]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF012AC1]
	(No symbol) [0x00007FF6DEFF6D83]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]

2024-04-14 22:19:13,441 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF012AC1]
	(No symbol) [0x00007FF6DEFF6D83]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF012AC1]
	(No symbol) [0x00007FF6DEFF6D83]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]

2024-04-14 22:19:13,441 - INFO - Started Scraping URL -> 2/2
2024-04-14 22:19:40,208 - INFO - Started Scraping URL -> 1/2
2024-04-14 22:19:43,479 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 22:19:43,482 - INFO - Started Scraping URL -> 2/2
2024-04-14 22:19:56,664 - INFO - Started Scraping URL -> 1/2
2024-04-14 22:20:04,530 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 22:21:58,891 - INFO - Started Scraping URL -> 2/2
2024-04-14 22:22:06,280 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 22:24:06,166 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF003CD2]
	(No symbol) [0x00007FF6DEFF6FA0]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 820, in get_owner_info
    auction_items = get_owner_info_gilchrist_realforeclose(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 896, in get_owner_info_gilchrist_realforeclose
    driver.close()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 456, in close
    self.execute(Command.CLOSE)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF6DF187032+63090]
	(No symbol) [0x00007FF6DF0F2C82]
	(No symbol) [0x00007FF6DEF8EC65]
	(No symbol) [0x00007FF6DEF6CA7C]
	(No symbol) [0x00007FF6DEFFD687]
	(No symbol) [0x00007FF6DF003CD2]
	(No symbol) [0x00007FF6DEFF6FA0]
	(No symbol) [0x00007FF6DEFC83A8]
	(No symbol) [0x00007FF6DEFC9441]
	GetHandleVerifier [0x00007FF6DF5825AD+4238317]
	GetHandleVerifier [0x00007FF6DF5BF70D+4488525]
	GetHandleVerifier [0x00007FF6DF5B79EF+4456495]
	GetHandleVerifier [0x00007FF6DF260576+953270]
	(No symbol) [0x00007FF6DF0FE54F]
	(No symbol) [0x00007FF6DF0F9224]
	(No symbol) [0x00007FF6DF0F935B]
	(No symbol) [0x00007FF6DF0E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]

2024-04-14 22:28:28,868 - INFO - Started Scraping URL -> 1/2
2024-04-14 22:28:42,827 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 22:31:40,945 - INFO - Started Scraping URL -> 2/2
2024-04-14 22:31:45,653 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 22:33:56,076 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF7C8287032+63090]
	(No symbol) [0x00007FF7C81F2C82]
	(No symbol) [0x00007FF7C808EC65]
	(No symbol) [0x00007FF7C806CA7C]
	(No symbol) [0x00007FF7C80FD687]
	(No symbol) [0x00007FF7C8103CD2]
	(No symbol) [0x00007FF7C80F6FA0]
	(No symbol) [0x00007FF7C80C83A8]
	(No symbol) [0x00007FF7C80C9441]
	GetHandleVerifier [0x00007FF7C86825AD+4238317]
	GetHandleVerifier [0x00007FF7C86BF70D+4488525]
	GetHandleVerifier [0x00007FF7C86B79EF+4456495]
	GetHandleVerifier [0x00007FF7C8360576+953270]
	(No symbol) [0x00007FF7C81FE54F]
	(No symbol) [0x00007FF7C81F9224]
	(No symbol) [0x00007FF7C81F935B]
	(No symbol) [0x00007FF7C81E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 837, in get_owner_info
    auction_items = get_owner_info_gilchrist_realforeclose(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 913, in get_owner_info_gilchrist_realforeclose
    driver.close()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 456, in close
    self.execute(Command.CLOSE)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF7C8287032+63090]
	(No symbol) [0x00007FF7C81F2C82]
	(No symbol) [0x00007FF7C808EC65]
	(No symbol) [0x00007FF7C806CA7C]
	(No symbol) [0x00007FF7C80FD687]
	(No symbol) [0x00007FF7C8103CD2]
	(No symbol) [0x00007FF7C80F6FA0]
	(No symbol) [0x00007FF7C80C83A8]
	(No symbol) [0x00007FF7C80C9441]
	GetHandleVerifier [0x00007FF7C86825AD+4238317]
	GetHandleVerifier [0x00007FF7C86BF70D+4488525]
	GetHandleVerifier [0x00007FF7C86B79EF+4456495]
	GetHandleVerifier [0x00007FF7C8360576+953270]
	(No symbol) [0x00007FF7C81FE54F]
	(No symbol) [0x00007FF7C81F9224]
	(No symbol) [0x00007FF7C81F935B]
	(No symbol) [0x00007FF7C81E9B94]
	BaseThreadInitThunk [0x00007FFD5D497344+20]
	RtlUserThreadStart [0x00007FFD5DEC26B1+33]

2024-04-14 22:42:11,648 - INFO - Started Scraping URL -> 1/1
2024-04-14 22:42:19,586 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-14 22:45:01,053 - INFO - Excel File mapwise status updated!!!
2024-04-14 23:28:05,357 - INFO - Started Scraping URL -> 1/2
2024-04-14 23:28:11,329 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 23:29:04,041 - INFO - Started Scraping URL -> 2/2
2024-04-14 23:29:13,272 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 23:41:55,267 - INFO - Started Scraping URL -> 1/2
2024-04-14 23:42:04,368 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-14 23:42:53,953 - INFO - Started Scraping URL -> 2/2
2024-04-14 23:42:57,349 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-14 23:55:58,701 - INFO - Excel File mapwise status updated!!!
2024-04-15 00:30:11,549 - INFO - Started Scraping URL -> 1/1
2024-04-15 00:30:14,206 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 00:32:28,596 - INFO - Started Scraping URL -> 1/1
2024-04-15 00:32:38,147 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 00:34:05,102 - INFO - Excel File mapwise status updated!!!
2024-04-15 00:36:14,455 - INFO - Started Scraping URL -> 1/1
2024-04-15 00:36:23,348 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 00:37:37,753 - INFO - Excel File mapwise status updated!!!
2024-04-15 00:41:40,376 - INFO - Started Scraping URL -> 1/1
2024-04-15 00:41:51,742 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 00:45:13,697 - INFO - Excel File mapwise status updated!!!
2024-04-15 01:56:14,118 - INFO - Started Scraping URL -> 1/1
2024-04-15 01:56:19,868 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 01:57:39,357 - INFO - Excel File mapwise status updated!!!
2024-04-15 01:59:14,689 - INFO - Started Scraping URL -> 1/1
2024-04-15 01:59:22,339 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 02:00:38,894 - INFO - Excel File mapwise status updated!!!
2024-04-15 02:02:21,626 - INFO - Started Scraping URL -> 1/1
2024-04-15 02:02:31,604 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 02:03:57,646 - INFO - Excel File mapwise status updated!!!
2024-04-15 23:20:51,314 - INFO - Started Scraping URL -> 1/2
2024-04-15 23:20:56,890 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-15 23:21:57,468 - INFO - Started Scraping URL -> 2/2
2024-04-15 23:22:11,800 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-15 23:23:56,984 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF6AACD7032+63090]
	(No symbol) [0x00007FF6AAC42C82]
	(No symbol) [0x00007FF6AAADEC65]
	(No symbol) [0x00007FF6AAB2499D]
	(No symbol) [0x00007FF6AAB24ADC]
	(No symbol) [0x00007FF6AAB65B37]
	(No symbol) [0x00007FF6AAB4701F]
	(No symbol) [0x00007FF6AAB63412]
	(No symbol) [0x00007FF6AAB46D83]
	(No symbol) [0x00007FF6AAB183A8]
	(No symbol) [0x00007FF6AAB19441]
	GetHandleVerifier [0x00007FF6AB0D25AD+4238317]
	GetHandleVerifier [0x00007FF6AB10F70D+4488525]
	GetHandleVerifier [0x00007FF6AB1079EF+4456495]
	GetHandleVerifier [0x00007FF6AADB0576+953270]
	(No symbol) [0x00007FF6AAC4E54F]
	(No symbol) [0x00007FF6AAC49224]
	(No symbol) [0x00007FF6AAC4935B]
	(No symbol) [0x00007FF6AAC39B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 782, in get_owner_info
    auction_items = get_owner_info_citrus_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1421, in get_owner_info_citrus_taxdeed
    parcel_id = WebDriverWait(driver, 10).until(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF6AACD7032+63090]
	(No symbol) [0x00007FF6AAC42C82]
	(No symbol) [0x00007FF6AAADEC65]
	(No symbol) [0x00007FF6AAB2499D]
	(No symbol) [0x00007FF6AAB24ADC]
	(No symbol) [0x00007FF6AAB65B37]
	(No symbol) [0x00007FF6AAB4701F]
	(No symbol) [0x00007FF6AAB63412]
	(No symbol) [0x00007FF6AAB46D83]
	(No symbol) [0x00007FF6AAB183A8]
	(No symbol) [0x00007FF6AAB19441]
	GetHandleVerifier [0x00007FF6AB0D25AD+4238317]
	GetHandleVerifier [0x00007FF6AB10F70D+4488525]
	GetHandleVerifier [0x00007FF6AB1079EF+4456495]
	GetHandleVerifier [0x00007FF6AADB0576+953270]
	(No symbol) [0x00007FF6AAC4E54F]
	(No symbol) [0x00007FF6AAC49224]
	(No symbol) [0x00007FF6AAC4935B]
	(No symbol) [0x00007FF6AAC39B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-15 23:26:04,654 - INFO - Started Scraping URL -> 1/2
2024-04-15 23:26:16,415 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-15 23:27:15,409 - INFO - Started Scraping URL -> 2/2
2024-04-15 23:27:27,477 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-15 23:36:25,311 - INFO - Started Scraping URL -> 1/1
2024-04-15 23:36:27,988 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 23:37:13,598 - INFO - Started Scraping URL -> 1/2
2024-04-15 23:37:16,309 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-15 23:37:29,899 - INFO - Started Scraping URL -> 2/2
2024-04-15 23:37:32,533 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-15 23:38:29,646 - INFO - Started Scraping URL -> 1/1
2024-04-15 23:38:37,344 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 23:41:27,884 - INFO - Started Scraping URL -> 1/1
2024-04-15 23:41:36,468 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-15 23:49:08,551 - INFO - Excel File mapwise status updated!!!
2024-04-15 23:57:08,998 - INFO - Started Scraping URL -> 1/1
2024-04-15 23:57:18,397 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-16 00:04:52,475 - INFO - Excel File mapwise status updated!!!
2024-04-16 00:13:58,342 - INFO - Started Scraping URL -> 1/1
2024-04-16 00:14:14,331 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-16 00:25:10,194 - INFO - Excel File mapwise status updated!!!
2024-04-16 00:40:05,995 - INFO - Started Scraping URL -> 1/2
2024-04-16 00:40:12,146 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 00:40:34,363 - INFO - Started Scraping URL -> 2/2
2024-04-16 00:40:44,633 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 00:42:40,825 - INFO - Started Scraping URL -> 1/2
2024-04-16 00:42:47,246 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 00:43:09,398 - INFO - Started Scraping URL -> 2/2
2024-04-16 00:43:14,907 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 00:44:15,034 - ERROR - Error Occurred in the main function: list index out of range
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 848, in get_owner_info
    auction_items = get_owner_info_alachua_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 944, in get_owner_info_alachua_realtaxdeed
    auction_items['first_name'] = owner_names_fl[1]
                                  ~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2024-04-16 00:44:38,992 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF6AACD7032+63090]
	(No symbol) [0x00007FF6AAC42C82]
	(No symbol) [0x00007FF6AAADEC65]
	(No symbol) [0x00007FF6AAB2499D]
	(No symbol) [0x00007FF6AAB24ADC]
	(No symbol) [0x00007FF6AAB65B37]
	(No symbol) [0x00007FF6AAB4701F]
	(No symbol) [0x00007FF6AAB63412]
	(No symbol) [0x00007FF6AAB46D83]
	(No symbol) [0x00007FF6AAB183A8]
	(No symbol) [0x00007FF6AAB19441]
	GetHandleVerifier [0x00007FF6AB0D25AD+4238317]
	GetHandleVerifier [0x00007FF6AB10F70D+4488525]
	GetHandleVerifier [0x00007FF6AB1079EF+4456495]
	GetHandleVerifier [0x00007FF6AADB0576+953270]
	(No symbol) [0x00007FF6AAC4E54F]
	(No symbol) [0x00007FF6AAC49224]
	(No symbol) [0x00007FF6AAC4935B]
	(No symbol) [0x00007FF6AAC39B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 848, in get_owner_info
    auction_items = get_owner_info_alachua_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 922, in get_owner_info_alachua_realtaxdeed
    owner_info_div = WebDriverWait(driver, 10).until(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF6AACD7032+63090]
	(No symbol) [0x00007FF6AAC42C82]
	(No symbol) [0x00007FF6AAADEC65]
	(No symbol) [0x00007FF6AAB2499D]
	(No symbol) [0x00007FF6AAB24ADC]
	(No symbol) [0x00007FF6AAB65B37]
	(No symbol) [0x00007FF6AAB4701F]
	(No symbol) [0x00007FF6AAB63412]
	(No symbol) [0x00007FF6AAB46D83]
	(No symbol) [0x00007FF6AAB183A8]
	(No symbol) [0x00007FF6AAB19441]
	GetHandleVerifier [0x00007FF6AB0D25AD+4238317]
	GetHandleVerifier [0x00007FF6AB10F70D+4488525]
	GetHandleVerifier [0x00007FF6AB1079EF+4456495]
	GetHandleVerifier [0x00007FF6AADB0576+953270]
	(No symbol) [0x00007FF6AAC4E54F]
	(No symbol) [0x00007FF6AAC49224]
	(No symbol) [0x00007FF6AAC4935B]
	(No symbol) [0x00007FF6AAC39B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 00:49:50,735 - INFO - Started Scraping URL -> 1/2
2024-04-16 00:49:57,031 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 00:50:19,516 - INFO - Started Scraping URL -> 2/2
2024-04-16 00:50:25,297 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 00:51:26,611 - INFO - Excel File mapwise status updated!!!
2024-04-16 00:55:05,306 - INFO - Started Scraping URL -> 1/2
2024-04-16 00:55:16,033 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 00:55:40,028 - INFO - Started Scraping URL -> 2/2
2024-04-16 00:55:46,717 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 00:58:15,185 - INFO - Started Scraping URL -> 1/2
2024-04-16 00:58:27,463 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 00:58:52,569 - INFO - Started Scraping URL -> 2/2
2024-04-16 00:58:59,474 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 01:00:59,285 - INFO - Excel File mapwise status updated!!!
2024-04-16 01:07:56,875 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:08:09,370 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 01:08:34,264 - INFO - Started Scraping URL -> 2/2
2024-04-16 01:08:46,092 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 01:10:17,519 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:10:24,639 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 01:10:47,551 - INFO - Started Scraping URL -> 2/2
2024-04-16 01:10:58,337 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 01:13:14,946 - INFO - Excel File mapwise status updated!!!
2024-04-16 01:25:57,927 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:26:05,354 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 01:26:51,586 - INFO - Started Scraping URL -> 2/2
2024-04-16 01:26:58,855 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 01:28:14,241 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E385B37]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 837, in get_owner_info
    auction_items = get_owner_info_marion_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 858, in get_owner_info_marion_realtaxdeed
    owner_info_element = WebDriverWait(driver, 10).until(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E385B37]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:28:50,678 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E385B37]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 837, in get_owner_info
    auction_items = get_owner_info_marion_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 858, in get_owner_info_marion_realtaxdeed
    owner_info_element = WebDriverWait(driver, 10).until(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E385B37]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:34:03,764 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:34:15,093 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 01:35:03,884 - INFO - Started Scraping URL -> 2/2
2024-04-16 01:35:08,344 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 01:38:31,303 - INFO - Excel File mapwise status updated!!!
2024-04-16 01:52:39,336 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:52:52,899 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 01:53:55,478 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 868, in get_owner_info_martin_realforeclose_and_taxdeed
    property_owner = general_info.find_element_by_xpath(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 01:54:09,349 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 868, in get_owner_info_martin_realforeclose_and_taxdeed
    property_owner = general_info.find_element_by_xpath(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 01:54:23,143 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 868, in get_owner_info_martin_realforeclose_and_taxdeed
    property_owner = general_info.find_element_by_xpath(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 01:54:35,858 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 868, in get_owner_info_martin_realforeclose_and_taxdeed
    property_owner = general_info.find_element_by_xpath(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 01:55:06,317 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:55:14,197 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 01:56:12,565 - ERROR - Error Occurred in the main function: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Property Owners']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 868, in get_owner_info_martin_realforeclose_and_taxdeed
    property_owner = general_info.find_element(By.XPATH,
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 417, in find_element
    return self._execute(Command.FIND_CHILD_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Property Owners']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:28,775 - ERROR - Error Occurred in the main function: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Property Owners']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 868, in get_owner_info_martin_realforeclose_and_taxdeed
    property_owner = general_info.find_element(By.XPATH,
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 417, in find_element
    return self._execute(Command.FIND_CHILD_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Property Owners']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,256 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'is_displayed'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 863, in get_owner_info_martin_realforeclose_and_taxdeed
    general_info = WebDriverWait(driver, 10).until(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 86, in until
    value = method(self._driver)
            ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 152, in _predicate
    return _element_if_visible(driver.find_element(*locator))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 175, in _element_if_visible
    return element if element.is_displayed() == visibility else False
                      ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'is_displayed'
2024-04-16 01:56:47,282 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,284 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,292 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,303 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,315 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,333 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,339 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,355 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 164, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=123.0.6312.107)
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E2DCA7C]
	(No symbol) [0x00007FF63E36D687]
	(No symbol) [0x00007FF63E382AC1]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 01:56:47,356 - INFO - Started Scraping URL -> 2/2
2024-04-16 01:59:44,138 - INFO - Started Scraping URL -> 1/2
2024-04-16 01:59:59,918 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 02:01:11,351 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 892, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element_by_xpath(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 02:01:23,325 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 892, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element_by_xpath(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 02:01:43,595 - ERROR - Error Occurred in the main function: 'WebElement' object has no attribute 'find_element_by_xpath'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 892, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element_by_xpath(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'WebElement' object has no attribute 'find_element_by_xpath'
2024-04-16 02:03:21,017 - INFO - Started Scraping URL -> 1/2
2024-04-16 02:03:32,985 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 02:04:38,074 - ERROR - Error Occurred in the main function: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 894, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element(By.XPATH,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 417, in find_element
    return self._execute(Command.FIND_CHILD_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 02:04:58,631 - ERROR - Error Occurred in the main function: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 894, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element(By.XPATH,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 417, in find_element
    return self._execute(Command.FIND_CHILD_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 02:05:16,008 - ERROR - Error Occurred in the main function: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 894, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element(By.XPATH,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 417, in find_element
    return self._execute(Command.FIND_CHILD_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 02:05:34,151 - ERROR - Error Occurred in the main function: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 278, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 842, in get_owner_info
    auction_items = get_owner_info_martin_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 894, in get_owner_info_martin_realforeclose_and_taxdeed
    mailing_address = general_info.find_element(By.XPATH,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 417, in find_element
    return self._execute(Command.FIND_CHILD_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//strong[text()='Mailing Address']/following-sibling::td"}
  (Session info: chrome=123.0.6312.107); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception
Stacktrace:
	GetHandleVerifier [0x00007FF63E4F7032+63090]
	(No symbol) [0x00007FF63E462C82]
	(No symbol) [0x00007FF63E2FEC65]
	(No symbol) [0x00007FF63E34499D]
	(No symbol) [0x00007FF63E344ADC]
	(No symbol) [0x00007FF63E33A0AC]
	(No symbol) [0x00007FF63E36701F]
	(No symbol) [0x00007FF63E33A00A]
	(No symbol) [0x00007FF63E3671F0]
	(No symbol) [0x00007FF63E383412]
	(No symbol) [0x00007FF63E366D83]
	(No symbol) [0x00007FF63E3383A8]
	(No symbol) [0x00007FF63E339441]
	GetHandleVerifier [0x00007FF63E8F25AD+4238317]
	GetHandleVerifier [0x00007FF63E92F70D+4488525]
	GetHandleVerifier [0x00007FF63E9279EF+4456495]
	GetHandleVerifier [0x00007FF63E5D0576+953270]
	(No symbol) [0x00007FF63E46E54F]
	(No symbol) [0x00007FF63E469224]
	(No symbol) [0x00007FF63E46935B]
	(No symbol) [0x00007FF63E459B94]
	BaseThreadInitThunk [0x00007FFCA75F7344+20]
	RtlUserThreadStart [0x00007FFCA94826B1+33]

2024-04-16 02:08:14,946 - INFO - Started Scraping URL -> 1/2
2024-04-16 02:08:25,355 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 02:09:30,675 - INFO - Started Scraping URL -> 2/2
2024-04-16 02:09:39,090 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 02:12:00,936 - INFO - Started Scraping URL -> 1/2
2024-04-16 02:12:10,599 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-16 02:13:19,980 - INFO - Started Scraping URL -> 2/2
2024-04-16 02:13:27,125 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-16 02:15:21,313 - INFO - Excel File mapwise status updated!!!
2024-04-16 03:08:25,093 - INFO - Started Scraping URL -> 1/1
2024-04-16 03:08:32,363 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-16 03:10:01,442 - INFO - Excel File mapwise status updated!!!
2024-04-16 03:10:42,551 - INFO - Started Scraping URL -> 1/1
2024-04-16 03:10:56,499 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-16 03:13:03,214 - INFO - Started Scraping URL -> 1/1
2024-04-16 03:13:12,837 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-16 03:14:28,986 - INFO - Excel File mapwise status updated!!!
2024-04-16 03:33:30,697 - INFO - Started Scraping URL -> 1/6
2024-04-16 03:33:42,458 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-16 03:34:24,554 - INFO - Started Scraping URL -> 2/6
2024-04-16 03:34:33,829 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-16 03:35:48,177 - INFO - Started Scraping URL -> 3/6
2024-04-16 03:35:54,191 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-16 03:36:29,968 - INFO - Started Scraping URL -> 4/6
2024-04-16 03:36:37,040 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-16 03:37:37,218 - INFO - Started Scraping URL -> 5/6
2024-04-16 03:37:44,516 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-16 03:38:40,544 - INFO - Started Scraping URL -> 6/6
2024-04-16 03:38:48,819 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-16 03:42:47,340 - INFO - Excel File mapwise status updated!!!
2024-04-20 23:16:15,894 - INFO - Started Scraping URL -> 1/6
2024-04-20 23:16:29,385 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-20 23:17:14,769 - INFO - Started Scraping URL -> 2/6
2024-04-20 23:17:26,563 - INFO - Getting Foreclosure Dates For -> 2/6
2024-04-20 23:19:06,021 - INFO - Started Scraping URL -> 3/6
2024-04-20 23:19:12,608 - INFO - Getting Foreclosure Dates For -> 3/6
2024-04-20 23:19:46,882 - INFO - Started Scraping URL -> 4/6
2024-04-20 23:19:55,089 - INFO - Getting Foreclosure Dates For -> 4/6
2024-04-20 23:21:09,889 - INFO - Started Scraping URL -> 5/6
2024-04-20 23:21:22,141 - INFO - Getting Foreclosure Dates For -> 5/6
2024-04-20 23:22:16,957 - INFO - Started Scraping URL -> 6/6
2024-04-20 23:22:25,051 - INFO - Getting Foreclosure Dates For -> 6/6
2024-04-20 23:33:13,212 - INFO - Started Scraping URL -> 1/6
2024-04-20 23:33:16,132 - INFO - Getting Foreclosure Dates For -> 1/6
2024-04-20 23:33:16,735 - INFO - Started Scraping URL -> 2/6
2024-04-20 23:36:28,639 - INFO - Started Scraping URL -> 1/12
2024-04-20 23:36:45,292 - INFO - Getting Foreclosure Dates For -> 1/12
2024-04-20 23:37:28,553 - INFO - Started Scraping URL -> 2/12
2024-04-20 23:37:43,000 - INFO - Getting Foreclosure Dates For -> 2/12
2024-04-20 23:39:29,658 - INFO - Started Scraping URL -> 3/12
2024-04-20 23:39:54,008 - INFO - Getting Foreclosure Dates For -> 3/12
2024-04-20 23:40:34,312 - INFO - Started Scraping URL -> 4/12
2024-04-20 23:41:02,596 - INFO - Getting Foreclosure Dates For -> 4/12
2024-04-20 23:42:32,969 - INFO - Started Scraping URL -> 5/12
2024-04-20 23:42:43,630 - INFO - Getting Foreclosure Dates For -> 5/12
2024-04-20 23:44:15,040 - INFO - Started Scraping URL -> 6/12
2024-04-20 23:45:06,767 - INFO - Getting Foreclosure Dates For -> 6/12
2024-04-20 23:49:13,944 - INFO - Started Scraping URL -> 7/12
2024-04-20 23:53:09,680 - INFO - Getting Foreclosure Dates For -> 7/12
2024-04-20 23:56:13,894 - INFO - Started Scraping URL -> 8/12
2024-04-20 23:59:12,676 - INFO - Getting Foreclosure Dates For -> 8/12
2024-04-21 00:01:30,405 - INFO - Started Scraping URL -> 9/12
2024-04-21 00:01:35,299 - INFO - Getting Foreclosure Dates For -> 9/12
2024-04-21 00:02:11,934 - INFO - Started Scraping URL -> 10/12
2024-04-21 00:02:18,374 - INFO - Getting Foreclosure Dates For -> 10/12
2024-04-21 00:02:51,732 - INFO - Started Scraping URL -> 11/12
2024-04-21 00:02:58,462 - INFO - Getting Foreclosure Dates For -> 11/12
2024-04-21 00:03:52,391 - INFO - Started Scraping URL -> 12/12
2024-04-21 00:04:01,515 - INFO - Getting Foreclosure Dates For -> 12/12
2024-04-21 00:18:42,980 - INFO - Excel File mapwise status updated!!!
2024-04-21 00:48:50,428 - INFO - Started Scraping URL -> 1/12
2024-04-21 00:48:56,257 - INFO - Getting Foreclosure Dates For -> 1/12
2024-04-21 00:49:39,299 - INFO - Started Scraping URL -> 2/12
2024-04-21 00:49:44,209 - INFO - Getting Foreclosure Dates For -> 2/12
2024-04-21 00:51:18,303 - INFO - Started Scraping URL -> 3/12
2024-04-21 00:51:25,511 - INFO - Getting Foreclosure Dates For -> 3/12
2024-04-21 00:52:00,310 - INFO - Started Scraping URL -> 4/12
2024-04-21 00:52:07,535 - INFO - Getting Foreclosure Dates For -> 4/12
2024-04-21 00:53:11,017 - INFO - Started Scraping URL -> 5/12
2024-04-21 00:53:16,276 - INFO - Getting Foreclosure Dates For -> 5/12
2024-04-21 00:54:12,350 - INFO - Started Scraping URL -> 6/12
2024-04-21 00:54:17,661 - INFO - Getting Foreclosure Dates For -> 6/12
2024-04-21 00:55:04,432 - INFO - Started Scraping URL -> 7/12
2024-04-21 00:55:11,327 - INFO - Getting Foreclosure Dates For -> 7/12
2024-04-21 00:55:57,997 - INFO - Started Scraping URL -> 8/12
2024-04-21 00:56:04,419 - INFO - Getting Foreclosure Dates For -> 8/12
2024-04-21 00:57:06,725 - INFO - Started Scraping URL -> 9/12
2024-04-21 00:57:12,434 - INFO - Getting Foreclosure Dates For -> 9/12
2024-04-21 00:57:50,462 - INFO - Started Scraping URL -> 10/12
2024-04-21 00:58:02,353 - INFO - Getting Foreclosure Dates For -> 10/12
2024-04-21 00:58:38,942 - INFO - Started Scraping URL -> 11/12
2024-04-21 00:58:45,307 - INFO - Getting Foreclosure Dates For -> 11/12
2024-04-21 00:59:41,034 - INFO - Started Scraping URL -> 12/12
2024-04-21 00:59:53,560 - INFO - Getting Foreclosure Dates For -> 12/12
2024-04-23 21:05:30,966 - INFO - Started Scraping URL -> 1/69
2024-04-23 21:05:40,120 - INFO - Getting Foreclosure Dates For -> 1/69
2024-04-23 21:06:31,746 - INFO - Started Scraping URL -> 2/69
2024-04-23 21:06:49,592 - INFO - Getting Foreclosure Dates For -> 2/69
2024-04-23 21:07:28,539 - INFO - Started Scraping URL -> 3/69
2024-04-23 21:07:39,232 - INFO - Getting Foreclosure Dates For -> 3/69
2024-04-23 21:08:05,838 - INFO - Started Scraping URL -> 1/69
2024-04-23 21:08:16,679 - INFO - Getting Foreclosure Dates For -> 1/69
2024-04-23 21:13:57,362 - INFO - Started Scraping URL -> 1/69
2024-04-23 21:14:07,220 - INFO - Getting Foreclosure Dates For -> 1/69
2024-04-23 23:18:35,875 - INFO - Started Scraping URL -> 1/69
2024-04-23 23:18:43,024 - INFO - Getting Foreclosure Dates For -> 1/69
2024-04-23 23:19:08,913 - INFO - Started Scraping URL -> 1/1
2024-04-23 23:19:14,765 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-25 23:52:48,934 - INFO - Started Scraping URL -> 1/1
2024-04-25 23:53:01,219 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-25 23:55:09,140 - INFO - Started Scraping URL -> 1/1
2024-04-25 23:55:15,328 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-25 23:56:17,735 - ERROR - Error Occurred in the main function: 'Selector' object has no attribute 'get_attribute'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 201, in main
    print(f"Auction row => {auc_row.get_attribute('outerHTML')}")
                            ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Selector' object has no attribute 'get_attribute'
2024-04-25 23:56:24,476 - ERROR - Error Occurred in the main function: 'Selector' object has no attribute 'get_attribute'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 201, in main
    print(f"Auction row => {auc_row.get_attribute('outerHTML')}")
                            ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Selector' object has no attribute 'get_attribute'
2024-04-25 23:58:17,854 - INFO - Started Scraping URL -> 1/1
2024-04-25 23:58:23,506 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-25 23:59:28,913 - ERROR - Error Occurred in the main function: Selector.get() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 201, in main
    print(f"Auction row => {auc_row.get('outerHTML')}")
                            ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Selector.get() takes 1 positional argument but 2 were given
2024-04-26 00:00:31,745 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:00:38,817 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:05:27,589 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:05:35,362 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:06:34,636 - ERROR - Error Occurred in the main function: 'Selector' object has no attribute 'find_element'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 206, in main
    parcel_id = auc_row.find_element(By.XPATH,
                ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Selector' object has no attribute 'find_element'
2024-04-26 00:07:59,334 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:08:04,188 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:09:19,528 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 220, in main
    ).get().strip()
            ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:11:06,563 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:11:11,235 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:12:22,232 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 219, in main
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:30:57,194 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:31:03,423 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:32:19,401 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 280, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:32:51,995 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:33:00,024 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:34:18,438 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 280, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:41:35,159 - INFO - Started Scraping URL -> 1/1
2024-04-26 00:41:44,697 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 00:43:09,180 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 280, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:45:36,063 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 280, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:47:44,406 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 280, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:51:38,715 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 323, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 00:52:08,152 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 280, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 01:02:59,338 - INFO - Excel File mapwise status updated!!!
2024-04-26 01:11:30,542 - INFO - Started Scraping URL -> 1/1
2024-04-26 01:11:39,633 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-26 01:33:51,827 - INFO - Started Scraping URL -> 1/2
2024-04-26 01:34:06,632 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-26 01:41:44,908 - INFO - Started Scraping URL -> 2/2
2024-04-26 01:41:57,171 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-26 01:43:34,439 - ERROR - Error Occurred in the main function: list index out of range
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 293, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 928, in get_owner_info
    auction_items = get_owner_info_miamidade_realforeclose(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1446, in get_owner_info_miamidade_realforeclose
    auction_items['full_name'] = owner_names[0]
                                 ~~~~~~~~~~~^^^
IndexError: list index out of range
2024-04-26 01:52:41,761 - INFO - Started Scraping URL -> 1/2
2024-04-26 01:52:56,584 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-26 01:54:13,682 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:54:19,419 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 01:54:31,741 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:54:41,135 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:54:55,220 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:55:15,982 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:55:30,734 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:55:44,388 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:55:58,639 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:56:10,473 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:56:26,491 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 333, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/orangeclerk.csv'
2024-04-26 01:57:21,347 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 01:59:29,037 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 02:04:28,874 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 364, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 02:04:53,438 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-26 02:05:13,807 - INFO - Started Scraping URL -> 2/2
2024-04-26 02:05:22,436 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-27 01:44:27,380 - INFO - Started Scraping URL -> 1/1
2024-04-27 01:44:33,053 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 01:50:15,072 - INFO - Started Scraping URL -> 1/1
2024-04-27 01:50:20,332 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 01:52:22,897 - INFO - Started Scraping URL -> 1/1
2024-04-27 01:52:28,466 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 01:59:34,078 - INFO - Started Scraping URL -> 1/1
2024-04-27 01:59:38,836 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:03:06,278 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:03:15,493 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:07:01,149 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:07:10,174 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:11:37,559 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:11:49,420 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:15:28,660 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:15:36,237 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:19:42,252 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:19:47,962 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:24:21,245 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:24:30,528 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:29:42,181 - INFO - Started Scraping URL -> 1/1
2024-04-27 02:29:47,194 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-27 02:35:02,272 - INFO - Started Scraping URL -> 1/2
2024-04-27 02:35:08,162 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-27 02:55:21,524 - INFO - Started Scraping URL -> 2/2
2024-04-27 02:55:29,928 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-27 02:56:32,821 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-27 02:59:18,170 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-27 03:01:17,374 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-27 03:05:09,392 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 364, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-27 03:05:40,257 - ERROR - Error Occurred in the main function: 'NoneType' object has no attribute 'strip'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 267, in main
    auction_items, parcel_id_url = get_orange_items(
                                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 321, in get_orange_items
    ).xpath('.//text()').get().strip()
                               ^^^^^
AttributeError: 'NoneType' object has no attribute 'strip'
2024-04-27 03:32:53,509 - INFO - Excel File mapwise status updated!!!
2024-04-27 22:42:31,573 - INFO - Started Scraping URL -> 1/2
2024-04-27 22:42:37,593 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-27 22:43:43,917 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-04-27 22:49:37,995 - INFO - Started Scraping URL -> 2/2
2024-04-27 22:49:47,653 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-27 23:45:19,794 - INFO - Started Scraping URL -> 1/2
2024-04-27 23:45:26,968 - INFO - Getting Foreclosure Dates For -> 1/2
2024-04-27 23:55:43,670 - INFO - Started Scraping URL -> 2/2
2024-04-27 23:55:47,616 - INFO - Getting Foreclosure Dates For -> 2/2
2024-04-27 23:58:23,056 - INFO - Started Scraping URL -> 1/1
2024-04-27 23:58:27,018 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-28 00:04:10,301 - INFO - Started Scraping URL -> 1/1
2024-04-28 00:04:18,007 - INFO - Getting Foreclosure Dates For -> 1/1
2024-04-28 00:08:06,873 - INFO - Excel File mapwise status updated!!!
2024-05-03 01:40:39,880 - INFO - Started Scraping URL -> 1/1
2024-05-03 01:40:43,621 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 01:47:31,259 - INFO - Started Scraping URL -> 1/1
2024-05-03 01:47:38,398 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 01:57:55,467 - INFO - Started Scraping URL -> 1/1
2024-05-03 01:58:00,176 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 02:09:21,401 - INFO - Started Scraping URL -> 1/1
2024-05-03 02:09:31,448 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 02:19:50,154 - INFO - Started Scraping URL -> 1/1
2024-05-03 02:19:54,432 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 02:20:48,618 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF611D21502+60802]
	(No symbol) [0x00007FF611C9AC02]
	(No symbol) [0x00007FF611B57CE4]
	(No symbol) [0x00007FF611BA6D4D]
	(No symbol) [0x00007FF611BA6E1C]
	(No symbol) [0x00007FF611BECE37]
	(No symbol) [0x00007FF611BCABBF]
	(No symbol) [0x00007FF611BEA224]
	(No symbol) [0x00007FF611BCA923]
	(No symbol) [0x00007FF611B98FEC]
	(No symbol) [0x00007FF611B99C21]
	GetHandleVerifier [0x00007FF61202411D+3217821]
	GetHandleVerifier [0x00007FF6120660B7+3488055]
	GetHandleVerifier [0x00007FF61205F03F+3459263]
	GetHandleVerifier [0x00007FF611DDB846+823494]
	(No symbol) [0x00007FF611CA5F9F]
	(No symbol) [0x00007FF611CA0EC4]
	(No symbol) [0x00007FF611CA1052]
	(No symbol) [0x00007FF611C918A4]
	BaseThreadInitThunk [0x00007FFB35E17344+20]
	RtlUserThreadStart [0x00007FFB37B226B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.py", line 303, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 998, in get_owner_info
    auction_items = get_owner_info_orange_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1018, in get_owner_info_orange_realtaxdeed
    property_owner = WebDriverWait(driver, 20).until(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF611D21502+60802]
	(No symbol) [0x00007FF611C9AC02]
	(No symbol) [0x00007FF611B57CE4]
	(No symbol) [0x00007FF611BA6D4D]
	(No symbol) [0x00007FF611BA6E1C]
	(No symbol) [0x00007FF611BECE37]
	(No symbol) [0x00007FF611BCABBF]
	(No symbol) [0x00007FF611BEA224]
	(No symbol) [0x00007FF611BCA923]
	(No symbol) [0x00007FF611B98FEC]
	(No symbol) [0x00007FF611B99C21]
	GetHandleVerifier [0x00007FF61202411D+3217821]
	GetHandleVerifier [0x00007FF6120660B7+3488055]
	GetHandleVerifier [0x00007FF61205F03F+3459263]
	GetHandleVerifier [0x00007FF611DDB846+823494]
	(No symbol) [0x00007FF611CA5F9F]
	(No symbol) [0x00007FF611CA0EC4]
	(No symbol) [0x00007FF611CA1052]
	(No symbol) [0x00007FF611C918A4]
	BaseThreadInitThunk [0x00007FFB35E17344+20]
	RtlUserThreadStart [0x00007FFB37B226B1+33]

2024-05-03 02:21:37,556 - INFO - Started Scraping URL -> 1/1
2024-05-03 02:21:47,789 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 02:32:34,997 - INFO - Started Scraping URL -> 1/1
2024-05-03 02:32:45,366 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 02:41:33,697 - INFO - Started Scraping URL -> 1/1
2024-05-03 02:41:57,205 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:01:51,499 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:01:54,943 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:05:38,029 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:05:45,641 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:15:31,946 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:15:37,713 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:21:35,438 - INFO - Excel File mapwise status updated!!!
2024-05-03 03:23:05,754 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:23:12,850 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:30:11,357 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:30:34,666 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:30:38,458 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:32:57,407 - INFO - Excel File mapwise status updated!!!
2024-05-03 03:33:29,354 - INFO - Started Scraping URL -> 1/1
2024-05-03 03:33:37,111 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-03 03:37:58,296 - INFO - Excel File mapwise status updated!!!
2024-05-17 04:09:19,542 - INFO - Started Scraping URL -> 1/1
2024-05-17 04:09:22,407 - INFO - Getting Foreclosure Dates For -> 1/1
2024-05-25 02:28:26,508 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:28:30,405 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:30:45,647 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:30:52,717 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:35:21,481 - INFO - Started Scraping URL -> 2/2
2024-05-25 02:35:31,076 - INFO - Getting Foreclosure Dates For -> 2/2
2024-05-25 02:42:48,091 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:43:04,031 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:43:06,853 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:43:06,861 - INFO - Started Scraping URL -> 2/2
2024-05-25 02:47:01,896 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:47:08,975 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:48:05,679 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-05-25 02:48:13,406 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-05-25 02:48:20,054 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-05-25 02:48:30,941 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-05-25 02:48:37,634 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-05-25 02:48:45,300 - ERROR - Error Occurred in the main function: [Errno 13] Permission denied: 'testing/mdade.csv'
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 335, in main
    df.to_csv(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\core\generic.py", line 3720, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\util\_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\format.py", line 1189, in to_csv
    csv_formatter.save()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\formats\csvs.py", line 241, in save
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\pandas\io\common.py", line 856, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: 'testing/mdade.csv'
2024-05-25 02:48:58,106 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:49:00,821 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:49:00,827 - INFO - Started Scraping URL -> 2/2
2024-05-25 02:49:04,729 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:51:24,449 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:51:35,773 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:54:20,292 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 290, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 988, in get_owner_info
    auction_items = get_owner_info_marion_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1138, in get_owner_info_marion_realtaxdeed
    owner_info_element = WebDriverWait(driver, 10).until(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]

2024-05-25 02:54:46,296 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 290, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 988, in get_owner_info
    auction_items = get_owner_info_marion_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1138, in get_owner_info_marion_realtaxdeed
    owner_info_element = WebDriverWait(driver, 10).until(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]

2024-05-25 02:55:03,804 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 290, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 988, in get_owner_info
    auction_items = get_owner_info_marion_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1138, in get_owner_info_marion_realtaxdeed
    owner_info_element = WebDriverWait(driver, 10).until(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]

2024-05-25 02:56:02,126 - ERROR - Error Occurred in the main function: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 290, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 988, in get_owner_info
    auction_items = get_owner_info_marion_realtaxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 1138, in get_owner_info_marion_realtaxdeed
    owner_info_element = WebDriverWait(driver, 10).until(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 95, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
	GetHandleVerifier [0x00007FF79B671F22+60322]
	(No symbol) [0x00007FF79B5ECE99]
	(No symbol) [0x00007FF79B4A7EBA]
	(No symbol) [0x00007FF79B4F7676]
	(No symbol) [0x00007FF79B4F773C]
	(No symbol) [0x00007FF79B53E967]
	(No symbol) [0x00007FF79B51C25F]
	(No symbol) [0x00007FF79B53BC80]
	(No symbol) [0x00007FF79B51BFC3]
	(No symbol) [0x00007FF79B4E9617]
	(No symbol) [0x00007FF79B4EA211]
	GetHandleVerifier [0x00007FF79B98946D+3301613]
	GetHandleVerifier [0x00007FF79B9D3693+3605267]
	GetHandleVerifier [0x00007FF79B9C9410+3563664]
	GetHandleVerifier [0x00007FF79B7242F6+790390]
	(No symbol) [0x00007FF79B5F74DF]
	(No symbol) [0x00007FF79B5F33D4]
	(No symbol) [0x00007FF79B5F3562]
	(No symbol) [0x00007FF79B5E2F6F]
	BaseThreadInitThunk [0x00007FF95EDD7344+20]
	RtlUserThreadStart [0x00007FF95FCA26B1+33]

2024-05-25 02:57:23,662 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:57:27,129 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 02:57:27,137 - INFO - Started Scraping URL -> 2/2
2024-05-25 02:57:47,332 - INFO - Started Scraping URL -> 1/2
2024-05-25 02:57:54,866 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 03:03:58,494 - INFO - Started Scraping URL -> 2/2
2024-05-25 03:04:05,199 - INFO - Getting Foreclosure Dates For -> 2/2
2024-05-25 03:37:13,864 - INFO - Started Scraping URL -> 1/2
2024-05-25 03:37:19,967 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-25 03:43:24,009 - INFO - Started Scraping URL -> 2/2
2024-05-25 03:43:27,680 - INFO - Getting Foreclosure Dates For -> 2/2
2024-05-28 21:33:06,013 - INFO - Started Scraping URL -> 1/2
2024-05-28 21:33:12,027 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-28 21:45:33,251 - INFO - Started Scraping URL -> 2/2
2024-05-28 21:45:43,338 - INFO - Getting Foreclosure Dates For -> 2/2
2024-05-29 22:21:31,370 - INFO - Started Scraping URL -> 1/2
2024-05-29 22:21:35,536 - INFO - Getting Foreclosure Dates For -> 1/2
2024-05-29 22:46:31,433 - INFO - Started Scraping URL -> 2/2
2024-05-29 22:46:45,649 - INFO - Getting Foreclosure Dates For -> 2/2
2024-05-31 03:08:34,299 - INFO - Started Scraping URL -> 1/1
2024-05-31 03:08:37,807 - INFO - Getting Foreclosure Dates For -> 1/1
2024-06-06 00:49:26,028 - INFO - Started Scraping URL -> 1/2
2024-06-06 00:49:28,740 - INFO - Getting Foreclosure Dates For -> 1/2
2024-06-06 00:49:32,461 - INFO - Started Scraping URL -> 2/2
2024-06-06 00:50:49,220 - INFO - Started Scraping URL -> 1/2
2024-06-06 00:50:53,567 - INFO - Getting Foreclosure Dates For -> 1/2
2024-06-06 00:51:49,907 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:52:06,846 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:52:30,591 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:52:53,213 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:53:03,837 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:53:13,030 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:53:28,419 - ERROR - Error Occurred in the main function: len() takes exactly one argument (0 given)
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 306, in main
    print(f"Total URLS Processed => {len()}")
                                     ^^^^^
TypeError: len() takes exactly one argument (0 given)
2024-06-06 00:54:26,417 - INFO - Started Scraping URL -> 1/2
2024-06-06 00:54:38,210 - INFO - Getting Foreclosure Dates For -> 1/2
2024-06-06 01:01:51,734 - INFO - Started Scraping URL -> 2/2
2024-06-06 01:01:57,562 - INFO - Getting Foreclosure Dates For -> 2/2
2024-06-06 01:50:51,130 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A8A812]
	(No symbol) [0x00007FF684A7C1E0]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 2144, in get_owner_info_escambia_realforeclose_and_taxdeed
    wait_for_element(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 741, in wait_for_element
    WebDriverWait(driver, wait_time).until(
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\wait.py", line 86, in until
    value = method(self._driver)
            ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\support\expected_conditions.py", line 82, in _predicate
    return driver.find_element(*locator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 739, in find_element
    return self.execute(Command.FIND_ELEMENT, {"using": by, "value": value})["value"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 213, in main
    auction_items = get_owner_info(
                    ^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 917, in get_owner_info
    auction_items = get_owner_info_escambia_realforeclose_and_taxdeed(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\helper_functions_v2.py", line 2149, in get_owner_info_escambia_realforeclose_and_taxdeed
    driver.close()
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 456, in close
    self.execute(Command.CLOSE)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A8A812]
	(No symbol) [0x00007FF684A7C1E0]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]

2024-06-06 01:50:51,219 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 154, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]

2024-06-06 01:50:51,222 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 154, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]

2024-06-06 01:50:51,225 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 154, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]

2024-06-06 01:50:51,228 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 154, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]

2024-06-06 01:50:51,231 - ERROR - Error Occurred in the main function: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1.py", line 154, in main
    driver.get(auction_link)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF684BD1F52+60322]
	(No symbol) [0x00007FF684B4CEC9]
	(No symbol) [0x00007FF684A07EBA]
	(No symbol) [0x00007FF6849DD5A5]
	(No symbol) [0x00007FF684A836B7]
	(No symbol) [0x00007FF684A9B331]
	(No symbol) [0x00007FF684A7BFC3]
	(No symbol) [0x00007FF684A49617]
	(No symbol) [0x00007FF684A4A211]
	GetHandleVerifier [0x00007FF684EE94AD+3301629]
	GetHandleVerifier [0x00007FF684F336D3+3605283]
	GetHandleVerifier [0x00007FF684F29450+3563680]
	GetHandleVerifier [0x00007FF684C84326+790390]
	(No symbol) [0x00007FF684B5750F]
	(No symbol) [0x00007FF684B53404]
	(No symbol) [0x00007FF684B53592]
	(No symbol) [0x00007FF684B42F9F]
	BaseThreadInitThunk [0x00007FF8D3F27344+20]
	RtlUserThreadStart [0x00007FF8D56026B1+33]

2024-06-06 01:51:01,370 - INFO - Started Scraping URL -> 1/2
2024-06-06 01:51:06,891 - INFO - Getting Foreclosure Dates For -> 1/2
2024-06-06 01:57:24,019 - INFO - Started Scraping URL -> 2/2
2024-06-06 01:57:30,010 - INFO - Getting Foreclosure Dates For -> 2/2
2024-06-07 01:00:42,519 - INFO - Started Scraping URL -> 1/2
2024-06-07 01:00:46,659 - INFO - Getting Foreclosure Dates For -> 1/2
2024-06-07 01:00:47,294 - INFO - Started Scraping URL -> 2/2
2024-06-07 01:00:47,296 - ERROR - Error in => https://escambia.realtaxdeed.com/index.cfm?resetcfcobjs=1 | Error: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF609601F52+60322]
	(No symbol) [0x00007FF60957CEC9]
	(No symbol) [0x00007FF609437EBA]
	(No symbol) [0x00007FF60940D5A5]
	(No symbol) [0x00007FF6094B36B7]
	(No symbol) [0x00007FF6094CB331]
	(No symbol) [0x00007FF6094ABFC3]
	(No symbol) [0x00007FF609479617]
	(No symbol) [0x00007FF60947A211]
	GetHandleVerifier [0x00007FF6099194AD+3301629]
	GetHandleVerifier [0x00007FF6099636D3+3605283]
	GetHandleVerifier [0x00007FF609959450+3563680]
	GetHandleVerifier [0x00007FF6096B4326+790390]
	(No symbol) [0x00007FF60958750F]
	(No symbol) [0x00007FF609583404]
	(No symbol) [0x00007FF609583592]
	(No symbol) [0x00007FF609572F9F]
	BaseThreadInitThunk [0x00007FFAED8E7344+20]
	RtlUserThreadStart [0x00007FFAEF7E26B1+33]
Traceback (most recent call last):
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\scraper_BOT-1_v3.1.1.1-test.py", line 422, in <module>
    driver.get(data['modified_url'])
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 354, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    self.error_handler.check_response(response)
  File "C:\Users\MAK\Documents\GitHub\scraper_BOT-1_v3\venv\Lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=125.0.6422.142)
Stacktrace:
	GetHandleVerifier [0x00007FF609601F52+60322]
	(No symbol) [0x00007FF60957CEC9]
	(No symbol) [0x00007FF609437EBA]
	(No symbol) [0x00007FF60940D5A5]
	(No symbol) [0x00007FF6094B36B7]
	(No symbol) [0x00007FF6094CB331]
	(No symbol) [0x00007FF6094ABFC3]
	(No symbol) [0x00007FF609479617]
	(No symbol) [0x00007FF60947A211]
	GetHandleVerifier [0x00007FF6099194AD+3301629]
	GetHandleVerifier [0x00007FF6099636D3+3605283]
	GetHandleVerifier [0x00007FF609959450+3563680]
	GetHandleVerifier [0x00007FF6096B4326+790390]
	(No symbol) [0x00007FF60958750F]
	(No symbol) [0x00007FF609583404]
	(No symbol) [0x00007FF609583592]
	(No symbol) [0x00007FF609572F9F]
	BaseThreadInitThunk [0x00007FFAED8E7344+20]
	RtlUserThreadStart [0x00007FFAEF7E26B1+33]

